{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8770bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER Tagging For Essay Claim Identification \n",
    "# Ambra, Nikki, and Drew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ad11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import cuda\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72cacf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'model_name': None,   \n",
    "         'max_length': 1024,\n",
    "         'train_batch_size':4,\n",
    "         'valid_batch_size':4,\n",
    "         'epochs':5,\n",
    "         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "         'max_grad_norm':10,\n",
    "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe154ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os \n",
    "import pandas as pd, gc \n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3070ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Shape: (144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "\n",
    "train_df = pd.read_csv('./feedback-prize-2021/train.csv')\n",
    "print(\"Train Dataset Shape:\", train_df.shape )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e108da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files & text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...\n",
       "1  DFEAEC512BAB  Should students design a summer project for sc...\n",
       "2  2E4AFCD3987F  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...\n",
       "3  EB6C2AF20BFE  People sometimes have a different opinion than...\n",
       "4  A91A08E523D5  Dear senator,\\n\\nAs you know the Electoral Col..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse through all the training files and makes a dataframe with columns ['train_ID (filename)', 'text']\n",
    "test_names, train_texts = [], []\n",
    "for file_name in list(os.listdir('./feedback-prize-2021/train')):\n",
    "    ID = file_name.replace('.txt', '')\n",
    "    train_text = open('./feedback-prize-2021/train/' + file_name, 'r').read()\n",
    "    \n",
    "    test_names.append(ID)\n",
    "    train_texts.append(train_text)\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "\n",
    "print(\"Training files & text\")\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea453ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object DataFrame.iterrows at 0x7fa0a97e2580>\n",
      "Computed Tags for 1000 essays\n",
      "Computed Tags for 2000 essays\n",
      "Computed Tags for 3000 essays\n",
      "Computed Tags for 4000 essays\n",
      "Computed Tags for 5000 essays\n",
      "Computed Tags for 6000 essays\n",
      "Computed Tags for 7000 essays\n",
      "Computed Tags for 8000 essays\n",
      "Computed Tags for 9000 essays\n",
      "Computed Tags for 10000 essays\n",
      "Computed Tags for 11000 essays\n",
      "Computed Tags for 12000 essays\n",
      "Computed Tags for 13000 essays\n",
      "Computed Tags for 14000 essays\n",
      "Computed Tags for 15000 essays\n"
     ]
    }
   ],
   "source": [
    "# Get the ground truth NER tags for all the texts \n",
    "all_entities = []\n",
    "print(train_text_df.iterrows())\n",
    "\n",
    "essay_num = 0\n",
    "for index, row in train_text_df.iterrows():\n",
    "    essay_num += 1\n",
    "    if (essay_num % 1000 == 0):\n",
    "        print(\"Computed Tags for\", essay_num, \"essays\")\n",
    "    \n",
    "    #initialize all tags to \"O\"\n",
    "    num_words_in_essay = len(row['text'].split())\n",
    "    entities = [\"O\"]*num_words_in_essay\n",
    "    \n",
    "    #Get Cooresponding ground truth rows\n",
    "    text_id = row[\"id\"]\n",
    "    cooresponding_ground_truth = train_df[train_df['id'] == text_id]\n",
    "    \n",
    "    for gt_ind, gt_row in cooresponding_ground_truth.iterrows():\n",
    "        discourse_type = gt_row['discourse_type']\n",
    "        prediction_string = gt_row['predictionstring']\n",
    "        \n",
    "        list_ix = [int(x) for x in prediction_string.split(' ')]\n",
    "        \n",
    "        beginning_index = list_ix[0]\n",
    "        entities[beginning_index] = \"B-\" + discourse_type\n",
    "        \n",
    "        for i in list_ix[1:]:\n",
    "            entities[i] = \"I-\" + discourse_type\n",
    "    all_entities.append(entities)\n",
    "    \n",
    "train_text_df['entities'] = all_entities\n",
    "train_text_df.to_csv('train_NER.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7c15067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth NER tags\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[O, O, O, O, B-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...   \n",
       "1  DFEAEC512BAB  Should students design a summer project for sc...   \n",
       "2  2E4AFCD3987F  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  EB6C2AF20BFE  People sometimes have a different opinion than...   \n",
       "4  A91A08E523D5  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "1  [O, O, O, O, O, O, O, O, B-Position, I-Positio...  \n",
       "2  [O, O, O, O, B-Position, I-Position, I-Positio...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ground truth NER tags\")\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9652b755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-Lead': 1,\n",
       " 'I-Lead': 2,\n",
       " 'B-Position': 3,\n",
       " 'I-Position': 4,\n",
       " 'B-Claim': 5,\n",
       " 'I-Claim': 6,\n",
       " 'B-Counterclaim': 7,\n",
       " 'I-Counterclaim': 8,\n",
       " 'B-Rebuttal': 9,\n",
       " 'I-Rebuttal': 10,\n",
       " 'B-Evidence': 11,\n",
       " 'I-Evidence': 12,\n",
       " 'B-Concluding Statement': 13,\n",
       " 'I-Concluding Statement': 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: CAN SIMPLIFY THIS MAYBE? (O, B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement')\n",
    "\n",
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n",
    "          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n",
    "ids_to_labels = {k:v for k,v in enumerate(output_labels)}\n",
    "labels_to_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a12bf",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ca3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from other import NERDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27110a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS = train_df[\"id\"].unique()\n",
    "\n",
    "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
    "\n",
    "data = train_text_df[['id','text', 'entities']]\n",
    "train_dataset = data.loc[data['id'].isin(IDS[train_idx]),['text', 'entities']].reset_index(drop=True)\n",
    "test_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f35e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15594, 3)\n",
      "TRAIN Dataset: (14034, 2)\n",
      "TEST Dataset: (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d727ca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[O, O, O, O, B-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Can you imagine a time in the future when no ...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Should students design a summer project for sc...   \n",
       "1  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "2  People sometimes have a different opinion than...   \n",
       "3  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "4  \"Can you imagine a time in the future when no ...   \n",
       "\n",
       "                                            entities  \n",
       "0  [O, O, O, O, O, O, O, O, B-Position, I-Positio...  \n",
       "1  [O, O, O, O, B-Position, I-Position, I-Positio...  \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "3  [O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b0dc997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>617D56A15483</td>\n",
       "      <td>Do you want to go on daily trips and help peop...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35279D8353D6</td>\n",
       "      <td>Dear TEACHER_NAME,\\n\\nI heard that you are pla...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3E2658E49362</td>\n",
       "      <td>So we can all agree that Venus is a very inter...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0A2EE9B6BF75</td>\n",
       "      <td>With the rise of technology in schools, many q...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...   \n",
       "1  617D56A15483  Do you want to go on daily trips and help peop...   \n",
       "2  35279D8353D6  Dear TEACHER_NAME,\\n\\nI heard that you are pla...   \n",
       "3  3E2658E49362  So we can all agree that Venus is a very inter...   \n",
       "4  0A2EE9B6BF75  With the rise of technology in schools, many q...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29085b",
   "metadata": {},
   "source": [
    "## Make Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffdfb302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "max_length = 1024\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\".\") \n",
    "training_set = NERDataset(train_dataset, tokenizer, max_length, False)\n",
    "testing_set = NERDataset(test_dataset, tokenizer, max_length, True)\n",
    "\n",
    "train_params = {'batch_size': 4,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 4,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 1,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "# # TEST DATASET\n",
    "#test_texts_set = NERDataset(test_texts, tokenizer, max_length, True)\n",
    "#test_texts_loader = DataLoader(test_texts_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc908d41",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20e816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/eecs487/lib/python3.9/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "loading configuration file ./config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"./config.json\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"transformers_version\": \"4.27.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "loading weights file ./pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BigBirdForTokenClassification.\n",
      "\n",
      "All the weights of BigBirdForTokenClassification were initialized from the model checkpoint at ./pytorch_model.bin.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigBirdForTokenClassification(\n",
       "  (bert): BigBirdModel(\n",
       "    (embeddings): BigBirdEmbeddings(\n",
       "      (word_embeddings): Embedding(50358, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BigBirdEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download an NER Tagger model -- BigBird I think\n",
    "from transformers import *\n",
    "\n",
    "config_model = AutoConfig.from_pretrained('./config.json') \n",
    "model = AutoModelForTokenClassification.from_pretrained('./pytorch_model.bin',config=config_model)\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c6ce5",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e523e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    #tr_preds, tr_labels = [], []\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    print(\"Length of loader: \", len(training_loader))\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        print(idx)\n",
    "        return\n",
    "        \n",
    "        ids = batch['input_ids'].to('cpu', dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to('cpu', dtype = torch.long)\n",
    "        labels = batch['labels'].to('cpu', dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
    "                               return_dict=False)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 1==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        #tr_labels.extend(labels)\n",
    "        #tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=10\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74ca75",
   "metadata": {},
   "source": [
    "## Run below to train own model from scratch (need GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "027ac230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training epoch: 1\n",
      "### LR = 2.5e-05\n",
      "\n",
      "Length of loader:  3509\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "### Training epoch: 2\n",
      "### LR = 2.5e-05\n",
      "\n",
      "Length of loader:  3509\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "### Training epoch: 3\n",
      "### LR = 2.5e-06\n",
      "\n",
      "Length of loader:  3509\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "### Training epoch: 4\n",
      "### LR = 2.5e-06\n",
      "\n",
      "Length of loader:  3509\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "### Training epoch: 5\n",
      "### LR = 2.5e-07\n",
      "\n",
      "Length of loader:  3509\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "\n",
    "#Do the training step\n",
    "num_epochs = 5\n",
    "learning_rates = [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"### Training epoch: {epoch + 1}\")\n",
    "    for g in optimizer.param_groups: \n",
    "        g['lr'] = learning_rates[epoch]\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'### LR = {lr}\\n')\n",
    "\n",
    "    train(epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773aa10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to save the model\n",
    "import random\n",
    "x = random.randint(0,123789174)\n",
    "\n",
    "torch.save(model.state_dict(), f'new_model_{x}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e30b16",
   "metadata": {},
   "source": [
    "## Run the cell below to load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab041a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "path = \"./bigbird_v26.pt\"\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8727cf",
   "metadata": {},
   "source": [
    "## Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5efeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(batch):         \n",
    "    # MOVE BATCH TO GPU AND INFER\n",
    "    ids = batch[\"input_ids\"].to('cpu')\n",
    "    mask = batch[\"attention_mask\"].to('cpu')\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "\n",
    "    # INTERATE THROUGH EACH TEXT AND GET PRED\n",
    "    predictions = []\n",
    "    for k,text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][k].numpy()  \n",
    "        previous_word_idx = -1\n",
    "        for idx,word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6de811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df=test_dataset, loader=testing_loader):\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.eval()\n",
    "    \n",
    "    # GET WORD LABEL PREDICTIONS\n",
    "    y_pred2 = []\n",
    "    for batch in loader:\n",
    "        labels = inference(batch)\n",
    "        print(labels)\n",
    "        print(1/0)\n",
    "        y_pred2.extend(labels)\n",
    "\n",
    "    final_preds2 = []\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        idx = df.id.values[i]\n",
    "        #pred = [x.replace('B-','').replace('I-','') for x in y_pred2[i]]\n",
    "        pred = y_pred2[i] # Leave \"B\" and \"I\"\n",
    "        preds = []\n",
    "        j = 0\n",
    "        while j < len(pred):\n",
    "            cls = pred[j]\n",
    "            if cls == 'O': j += 1\n",
    "            else: cls = cls.replace('B','I') # spans start with B\n",
    "            end = j + 1\n",
    "            while end < len(pred) and pred[end] == cls:\n",
    "                end += 1\n",
    "            \n",
    "            if cls != 'O' and cls != '' and end - j > 7:\n",
    "                final_preds2.append((idx, cls.replace('I-',''),\n",
    "                                     ' '.join(map(str, list(range(j, end))))))\n",
    "        \n",
    "            j = end\n",
    "        \n",
    "    oof = pd.DataFrame(final_preds2)\n",
    "    oof.columns = ['id','class','predictionstring']\n",
    "\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1272479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement'], ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'O', 'O', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement'], ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'B-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Claim', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement'], ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Evidence', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'O', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Evidence', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Evidence', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence']]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_texts_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(df, loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m     labels \u001b[38;5;241m=\u001b[39m inference(batch)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m     y_pred2\u001b[38;5;241m.\u001b[39mextend(labels)\n\u001b[1;32m     14\u001b[0m final_preds2 \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "sub = get_predictions(test_texts, test_texts_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44234fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>36.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>The ability to stay connected to people we kno...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>513.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>However, this device is taken to areas that i...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>92 93 94 95 96 97 98 99 100 101 102 103 104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>594.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>Within a vehicle capable of traveling upwards ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>105 106 107 108 109 110 111 112 113 114 115 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>The most common of these distractions is a cel...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>125 126 127 128 129 130 131 132 133 134 135 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>Conversely people may believe that laws in pre...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>221 222 223 224 225 226 227 228 229 230 231 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144256</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>1.618239e+12</td>\n",
       "      <td>277.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>they will have more information on the situati...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>44 45 46 47 48 49 50 51 52 53 54 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144257</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>1.618239e+12</td>\n",
       "      <td>462.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>I was having trouble deciding what I should do...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144258</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>1.618239e+12</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>I was going to wear an outfit, but I could no...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>151 152 153 154 155 156 157 158 159 160 161 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144259</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>1.618239e+12</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>My family could not decide where to go for va...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>247 248 249 250 251 252 253 254 255 256 257 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144260</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>1.618239e+12</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>2113.0</td>\n",
       "      <td>By gathering different opinions it will help p...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>315 316 317 318 319 320 321 322 323 324 325 32...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14699 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "14      6B4F7A0165B9  1.622644e+12             36.0          512.0   \n",
       "15      6B4F7A0165B9  1.622644e+12            513.0          593.0   \n",
       "16      6B4F7A0165B9  1.622644e+12            594.0          726.0   \n",
       "17      6B4F7A0165B9  1.622644e+12            727.0         1244.0   \n",
       "18      6B4F7A0165B9  1.622644e+12           1245.0         1439.0   \n",
       "...              ...           ...              ...            ...   \n",
       "144256  6B5809C83978  1.618239e+12            277.0          349.0   \n",
       "144257  6B5809C83978  1.618239e+12            462.0          657.0   \n",
       "144258  6B5809C83978  1.618239e+12            910.0         1162.0   \n",
       "144259  6B5809C83978  1.618239e+12           1427.0         1688.0   \n",
       "144260  6B5809C83978  1.618239e+12           1804.0         2113.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "14      The ability to stay connected to people we kno...   \n",
       "15       However, this device is taken to areas that i...   \n",
       "16      Within a vehicle capable of traveling upwards ...   \n",
       "17      The most common of these distractions is a cel...   \n",
       "18      Conversely people may believe that laws in pre...   \n",
       "...                                                   ...   \n",
       "144256  they will have more information on the situati...   \n",
       "144257  I was having trouble deciding what I should do...   \n",
       "144258   I was going to wear an outfit, but I could no...   \n",
       "144259   My family could not decide where to go for va...   \n",
       "144260  By gathering different opinions it will help p...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "14                      Lead                  Lead 1   \n",
       "15                  Position              Position 1   \n",
       "16                     Claim                 Claim 1   \n",
       "17                  Evidence              Evidence 1   \n",
       "18              Counterclaim          Counterclaim 1   \n",
       "...                      ...                     ...   \n",
       "144256                 Claim                 Claim 3   \n",
       "144257              Evidence              Evidence 1   \n",
       "144258              Evidence              Evidence 2   \n",
       "144259              Evidence              Evidence 3   \n",
       "144260  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  \n",
       "14      5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ...  \n",
       "15            92 93 94 95 96 97 98 99 100 101 102 103 104  \n",
       "16      105 106 107 108 109 110 111 112 113 114 115 11...  \n",
       "17      125 126 127 128 129 130 131 132 133 134 135 13...  \n",
       "18      221 222 223 224 225 226 227 228 229 230 231 23...  \n",
       "...                                                   ...  \n",
       "144256                44 45 46 47 48 49 50 51 52 53 54 55  \n",
       "144257  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 8...  \n",
       "144258  151 152 153 154 155 156 157 158 159 160 161 16...  \n",
       "144259  247 248 249 250 251 252 253 254 255 256 257 25...  \n",
       "144260  315 316 317 318 319 320 321 322 323 324 325 32...  \n",
       "\n",
       "[14699 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n",
    "valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97196e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560\n",
      "14699\n",
      "1560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>617D56A15483</td>\n",
       "      <td>Do you want to go on daily trips and help peop...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35279D8353D6</td>\n",
       "      <td>Dear TEACHER_NAME,\\n\\nI heard that you are pla...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3E2658E49362</td>\n",
       "      <td>So we can all agree that Venus is a very inter...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0A2EE9B6BF75</td>\n",
       "      <td>With the rise of technology in schools, many q...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...   \n",
       "1  617D56A15483  Do you want to go on daily trips and help peop...   \n",
       "2  35279D8353D6  Dear TEACHER_NAME,\\n\\nI heard that you are pla...   \n",
       "3  3E2658E49362  So we can all agree that Venus is a very inter...   \n",
       "4  0A2EE9B6BF75  With the rise of technology in schools, many q...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(valid_idx))\n",
    "valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n",
    "print(len(valid))\n",
    "print(len(valid['id'].unique()))\n",
    "\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40942077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Ground truth labels\n",
      "Calculated gt labels for 1560 essays\n",
      "\n",
      "Getting the predicted labels\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "starting 0th batch out of 390\n",
      "starting 1th batch out of 390\n",
      "starting 2th batch out of 390\n",
      "starting 3th batch out of 390\n",
      "starting 4th batch out of 390\n",
      "starting 5th batch out of 390\n",
      "{'input_ids': tensor([ 65, 415, 567,  ...,   0,   0,   0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 2242,  446,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521, 13469,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1507,  457,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 2181,  363,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 2874, 4367,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 32527,   561,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1968,  567,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1419,  490,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 2242,  446,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1419,  490,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521,  1282,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 25378,   490,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65,  484, 1873,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 8293,  446,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1776,  717,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([ 65, 415, 408,  ...,   0,   0,   0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 1750,  446,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521,  1913,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521, 10134,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65,   321, 32313,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  0,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 3668,  990,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  0,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521,  1282,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 42809,   419,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521, 41022,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 3500, 3791,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 23521, 41022,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65,   871, 15609,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65, 4481,  388,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 25378,   524,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([  65,  484, 1067,  ...,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  1,  ..., -1, -1, -1])}\n",
      "{'input_ids': tensor([   65, 12535,  1304,  ...,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'wids': tensor([-1,  0,  0,  ..., -1, -1, -1])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Ground truth labels\")\n",
    "gt_labels = []\n",
    "for i, row in test_dataset.iterrows():\n",
    "    gt_labels.append(row['entities'])\n",
    "print(f\"Calculated gt labels for {len(gt_labels)} essays\")\n",
    "    \n",
    "print()\n",
    "print(\"Getting the predicted labels\")\n",
    "pred_labels = []\n",
    "for i, batch in enumerate(testing_loader):\n",
    "    print(f\"starting {i} batch out of {len(testing_loader)}\")\n",
    "    labels = inference(batch)\n",
    "    for essay_prediction in labels:\n",
    "        pred_labels.append(essay_prediction)\n",
    "        \n",
    "    if (i == 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d384a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated gt labels for 24 essays\n",
      "Calculated pred labels for 24 essays\n",
      "The accuracy on the validation set is 0.9125361620057859\n"
     ]
    }
   ],
   "source": [
    "from hmm import get_accuracy\n",
    "\n",
    "gt_labels2 = gt_labels[:24]\n",
    "\n",
    "print(f\"Calculated gt labels for {len(gt_labels2)} essays\")\n",
    "print(f\"Calculated pred labels for {len(pred_labels)} essays\")\n",
    "\n",
    "print(\"The accuracy on the validation set is\", get_accuracy(pred_labels, gt_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b3dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
